{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N8XuizLedCc"
      },
      "source": [
        "# Assignment 3: Build a seq2seq model for machine translation.\n",
        "\n",
        "### Name: Amena Akbary\n",
        "\n",
        "### Task: Change LSTM model to Bidirectional LSTM Model and Translate English to Spanish\n",
        "\n",
        "### Due Date: Wednesday, April 17th, 11:59PM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpqnzXTVedCd"
      },
      "source": [
        "## 0. You will do the following:\n",
        "\n",
        "1. Read and run the code. Please make sure you have installed keras or tensorflow.Running the script on colab will speed up the training process and also prevent package loading issue.\n",
        "2. Complete the code in Section 1.1, you may fill in your data directory.\n",
        "3. Directly modify the code in Section 3. Change the current LSTM layer to a Bidirectional LSTM Model.\n",
        "4. Training your model and translate English to Spanish in Section 4.2. You could try translating other languages.\n",
        "5. Complete the code in Section 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJssi6rnedCe"
      },
      "source": [
        "### Hint:\n",
        "\n",
        "To implement ```Bi-LSTM```, you will need the following code to build the encoder **in Section 3**. Do NOT use Bi-LSTM for the decoder. But there are other codes **you need to modify** to make it work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dglRX36aedCe"
      },
      "outputs": [],
      "source": [
        "# from keras.layers import Bidirectional, Concatenate\n",
        "\n",
        "# encoder_bilstm = Bidirectional(LSTM(latent_dim, return_state=True,\n",
        "#                                   dropout=0.5, name='encoder_lstm'))\n",
        "# _, forward_h, forward_c, backward_h, backward_c = encoder_bilstm(encoder_inputs)\n",
        "\n",
        "# state_h = Concatenate()([forward_h, backward_h])\n",
        "# state_c = Concatenate()([forward_c, backward_c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-Ep4HhDedCe"
      },
      "source": [
        "## 1. Data preparation (10 points)\n",
        "\n",
        "1. Download spanish-english data from http://www.manythings.org/anki/\n",
        "2. You may try to use other languages.\n",
        "3. Unzip the .ZIP file.\n",
        "4. Put the .TXT file (e.g., \"deu.txt\") in the directory \"./Data/\".\n",
        "5. Fill in your data directory in section 1.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcInT6gmedCf"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from unicodedata import normalize\n",
        "import numpy\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "\n",
        "# split a loaded document into sentences\n",
        "def to_pairs(doc):\n",
        "    lines = doc.strip().split('\\n')\n",
        "    pairs = [line.split('\\t') for line in  lines]\n",
        "    return pairs\n",
        "\n",
        "def clean_data(lines):\n",
        "    cleaned = list()\n",
        "    # prepare regex for char filtering\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    # prepare translation table for removing punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for pair in lines:\n",
        "        clean_pair = list()\n",
        "        for line in pair:\n",
        "            # normalize unicode characters\n",
        "            line = normalize('NFD', line).encode('ascii', 'ignore')\n",
        "            line = line.decode('UTF-8')\n",
        "            # tokenize on white space\n",
        "            line = line.split()\n",
        "            # convert to lowercase\n",
        "            line = [word.lower() for word in line]\n",
        "            # remove punctuation from each token\n",
        "            line = [word.translate(table) for word in line]\n",
        "            # remove non-printable chars form each token\n",
        "            line = [re_print.sub('', w) for w in line]\n",
        "            # remove tokens with numbers in them\n",
        "            line = [word for word in line if word.isalpha()]\n",
        "            # store as string\n",
        "            clean_pair.append(' '.join(line))\n",
        "        cleaned.append(clean_pair)\n",
        "    return numpy.array(cleaned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChJPgfZBedCf"
      },
      "source": [
        "#### Fill the following blanks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCoHNXwYedCf"
      },
      "outputs": [],
      "source": [
        "# e.g., filename = 'Data/deu.txt'\n",
        "filename = '/content/spa.txt'\n",
        "\n",
        "# e.g., n_train = 20000\n",
        "n_train = 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWqZ2Ul5edCf"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "doc = load_doc(filename)\n",
        "\n",
        "# split into Language1-Language2 pairs\n",
        "pairs = to_pairs(doc)\n",
        "\n",
        "# clean sentences\n",
        "clean_pairs = clean_data(pairs)[0:n_train, :]\n",
        "\n",
        "\n",
        "# clean_pairs = clean_data(pairs)\n",
        "# n_examples = clean_pairs.shape[0]\n",
        "# start_index = min(n_examples, 3000)\n",
        "# end_index = min(n_examples, 3010)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox-E_ypqedCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ee5442-5854-4836-b824-0626d52521e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[we are here] => [estamos aqui]\n",
            "[we ate eggs] => [hemos comido huevos]\n",
            "[we ate eggs] => [comimos huevos]\n",
            "[we broke up] => [nos separamos]\n",
            "[we broke up] => [lo dejamos]\n",
            "[we broke up] => [rompimos]\n",
            "[we can help] => [podemos ayudar]\n",
            "[we can help] => [nosotros podemos ayudar]\n",
            "[we can meet] => [podemos encontrarnos]\n",
            "[we can meet] => [podemos vernos]\n"
          ]
        }
      ],
      "source": [
        "for i in range(3000, 3010):\n",
        "    print('[' + clean_pairs[i, 0] + '] => [' + clean_pairs[i, 1] + ']')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU0LP76redCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9513e463-784f-4750-e822-0cc6dcfe038a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of input_texts:  (20000,)\n",
            "Length of target_texts: (20000,)\n"
          ]
        }
      ],
      "source": [
        "input_texts = clean_pairs[:, 0]\n",
        "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]\n",
        "\n",
        "print('Length of input_texts:  ' + str(input_texts.shape))\n",
        "print('Length of target_texts: ' + str(input_texts.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dCvkueqedCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fabc679-117b-4a1c-aa20-d0d2f58cd765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max length of input  sentences: 18\n",
            "max length of target sentences: 48\n"
          ]
        }
      ],
      "source": [
        "max_encoder_seq_length = max(len(line) for line in input_texts)\n",
        "max_decoder_seq_length = max(len(line) for line in target_texts)\n",
        "\n",
        "print('max length of input  sentences: %d' % (max_encoder_seq_length))\n",
        "print('max length of target sentences: %d' % (max_decoder_seq_length))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE04yw06edCf"
      },
      "source": [
        "**Remark:** To this end, you have two lists of sentences: input_texts and target_texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6YdrJhTedCg"
      },
      "source": [
        "## 2. Text processing\n",
        "\n",
        "### 2.1. Convert texts to sequences\n",
        "\n",
        "- Input: A list of $n$ sentences (with max length $t$).\n",
        "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "Ww_GKnxa9U3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ef119a-d5eb-4ef3-e3fc-611a3493936d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT3e3qEXedCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df60358b-2361-4f96-f858-d46afcd4fb47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of encoder_input_seq: (20000, 18)\n",
            "shape of input_token_index: 27\n",
            "shape of decoder_input_seq: (20000, 48)\n",
            "shape of target_token_index: 29\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# encode and pad sequences\n",
        "def text2sequences(max_len, lines):\n",
        "    tokenizer = Tokenizer(char_level=True, filters='')\n",
        "    tokenizer.fit_on_texts(lines)\n",
        "    seqs = tokenizer.texts_to_sequences(lines)\n",
        "    seqs_pad = pad_sequences(seqs, maxlen=max_len, padding='post')\n",
        "    return seqs_pad, tokenizer.word_index\n",
        "\n",
        "\n",
        "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length,\n",
        "                                                      input_texts)\n",
        "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length,\n",
        "                                                       target_texts)\n",
        "\n",
        "print('shape of encoder_input_seq: ' + str(encoder_input_seq.shape))\n",
        "print('shape of input_token_index: ' + str(len(input_token_index)))\n",
        "print('shape of decoder_input_seq: ' + str(decoder_input_seq.shape))\n",
        "print('shape of target_token_index: ' + str(len(target_token_index)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcPKeQRqedCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd310270-5610-42e4-d5a8-7be43a428d24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_encoder_tokens: 28\n",
            "num_decoder_tokens: 30\n"
          ]
        }
      ],
      "source": [
        "num_encoder_tokens = len(input_token_index) + 1\n",
        "num_decoder_tokens = len(target_token_index) + 1\n",
        "\n",
        "print('num_encoder_tokens: ' + str(num_encoder_tokens))\n",
        "print('num_decoder_tokens: ' + str(num_decoder_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhoKzMHJedCg"
      },
      "source": [
        "**Remark:** To this end, the input language and target language texts are converted to 2 matrices.\n",
        "\n",
        "- Their number of rows are both n_train.\n",
        "- Their number of columns are respective max_encoder_seq_length and max_decoder_seq_length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER0xZXj0edCg"
      },
      "source": [
        "The followings print a sentence and its representation as a sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-kHFy8fedCg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d10f5dc1-e9b7-4882-ac65-9fdf68aee6e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\tentendiste\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "target_texts[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-3MdSEjedCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09707edd-1e3d-42ea-b84e-c768dde9d183"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  2,  9,  8,  2,  9, 15, 11,  5,  8,  2,  7,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "decoder_input_seq[100, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntQXp03iedCg"
      },
      "source": [
        "## 2.2. One-hot encode\n",
        "\n",
        "- Input: A list of $n$ sentences (with max length $t$).\n",
        "- It is represented by a $n\\times t$ matrix after the tokenization and zero-padding.\n",
        "- It is represented by a $n\\times t \\times v$ tensor ($t$ is the number of unique chars) after the one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSg79wQZedCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37488f2c-51ba-4da5-f298-5219b904dbc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 18, 28)\n",
            "(20000, 48, 30)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# one hot encode target sequence\n",
        "def onehot_encode(sequences, max_len, vocab_size):\n",
        "    n = len(sequences)\n",
        "    data = numpy.zeros((n, max_len, vocab_size))\n",
        "    for i in range(n):\n",
        "        data[i, :, :] = to_categorical(sequences[i], num_classes=vocab_size)\n",
        "    return data\n",
        "\n",
        "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_encoder_tokens)\n",
        "decoder_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
        "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
        "decoder_target_data = onehot_encode(decoder_target_seq,\n",
        "                                    max_decoder_seq_length,\n",
        "                                    num_decoder_tokens)\n",
        "\n",
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsPca3ARedCg"
      },
      "source": [
        "## 3. Build the networks (for training) (20 points)\n",
        "\n",
        "- In this section, we have already implemented the LSTM model for you. You can run the code and see what the code is doing.  \n",
        "\n",
        "- **You need to change the existing LSTM model to a Bidirectional LSTM model. Just modify the network structure and do not change the training cell in section 3.4.**\n",
        "\n",
        "- Build encoder, decoder, and connect the two modules to get \"model\".\n",
        "\n",
        "- Fit the model on the bilingual data to train the parameters in the encoder and decoder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXA8VeQTedCg"
      },
      "source": [
        "### 3.1. Encoder network\n",
        "\n",
        "- Input:  one-hot encode of the input language\n",
        "\n",
        "- Return:\n",
        "\n",
        "    -- output (all the hidden states   $h_1, \\cdots , h_t$) are always discarded\n",
        "    \n",
        "    -- the final hidden state  $h_t$\n",
        "    \n",
        "    -- the final conveyor belt $c_t$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWSGCibbedCh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.layers import Bidirectional, Concatenate\n",
        "\n",
        "latent_dim = 256\n",
        "\n",
        "# inputs of the encoder network\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens),\n",
        "                       name='encoder_inputs')\n",
        "\n",
        "# set the LSTM layer\n",
        "# encoder_lstm = LSTM(latent_dim, return_state=True,\n",
        "#                     dropout=0.5, name='encoder_lstm')\n",
        "# _, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "#set the Bi-LSTM layer\n",
        "encoder_bi_lstm = Bidirectional(LSTM(latent_dim, return_state=True, dropout=0.5, name='encoder_lstm'), name='encode_bi_lstm')\n",
        "\n",
        "#getting outputs and states of Bi-LSTM\n",
        "encoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_bi_lstm(encoder_inputs)\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "state_c = Concatenate()([forward_c, backward_c])\n",
        "\n",
        "# build the encoder network model\n",
        "encoder_model = Model(inputs=encoder_inputs,\n",
        "                      outputs=[state_h, state_c],\n",
        "                      name='encoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBBFxciGedCh"
      },
      "source": [
        "Print a summary and save the encoder network structure to \"./encoder.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-0dROLFedCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4ed2d6d-1595-4181-bdfd-4bf1716c010b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer  [(None, None, 28)]           0         []                            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " encode_bi_lstm (Bidirectio  [(None, 512),                583680    ['encoder_inputs[0][0]']      \n",
            " nal)                         (None, 256),                                                        \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 512)                  0         ['encode_bi_lstm[0][1]',      \n",
            "                                                                     'encode_bi_lstm[0][3]']      \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 512)                  0         ['encode_bi_lstm[0][2]',      \n",
            " )                                                                   'encode_bi_lstm[0][4]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 583680 (2.23 MB)\n",
            "Trainable params: 583680 (2.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(encoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
        "\n",
        "plot_model(\n",
        "    model=encoder_model, show_shapes=False,\n",
        "    to_file='encoder.pdf'\n",
        ")\n",
        "\n",
        "encoder_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu24I0tIedCh"
      },
      "source": [
        "### 3.2. Decoder network\n",
        "\n",
        "- Inputs:  \n",
        "\n",
        "    -- one-hot encode of the target language\n",
        "    \n",
        "    -- The initial hidden state $h_t$\n",
        "    \n",
        "    -- The initial conveyor belt $c_t$\n",
        "\n",
        "- Return:\n",
        "\n",
        "    -- output (all the hidden states) $h_1, \\cdots , h_t$\n",
        "\n",
        "    -- the final hidden state  $h_t$ (discarded in the training and used in the prediction)\n",
        "    \n",
        "    -- the final conveyor belt $c_t$ (discarded in the training and used in the prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaiRZWG9edCh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#adjusting the latent dimensions to handle concatenated forward and backward states\n",
        "latent_dim = 256\n",
        "decoder_latent_dim = 2 * latent_dim\n",
        "\n",
        "# inputs of the decoder network\n",
        "decoder_input_h = Input(shape=(decoder_latent_dim,), name='decoder_input_h')\n",
        "decoder_input_c = Input(shape=(decoder_latent_dim,), name='decoder_input_c')\n",
        "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
        "\n",
        "# set the LSTM layer\n",
        "decoder_lstm = LSTM(decoder_latent_dim, return_sequences=True,\n",
        "                    return_state=True, dropout=0.5, name='decoder_lstm')\n",
        "decoder_lstm_outputs, state_h, state_c = decoder_lstm(decoder_input_x,\n",
        "                                                      initial_state=[decoder_input_h, decoder_input_c])\n",
        "\n",
        "# set the dense layer\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
        "\n",
        "# build the decoder network model\n",
        "decoder_model = Model(inputs=[decoder_input_x, decoder_input_h, decoder_input_c],\n",
        "                      outputs=[decoder_outputs, state_h, state_c],\n",
        "                      name='decoder')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vDWdyNtedCh"
      },
      "source": [
        "Print a summary and save the encoder network structure to \"./decoder.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2Jo7bPyedCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32702d0-a6dd-489b-ea00-60640eced561"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"decoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " decoder_input_x (InputLaye  [(None, None, 30)]           0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " decoder_input_h (InputLaye  [(None, 512)]                0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " decoder_input_c (InputLaye  [(None, 512)]                0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, None, 512),          1112064   ['decoder_input_x[0][0]',     \n",
            "                              (None, 512),                           'decoder_input_h[0][0]',     \n",
            "                              (None, 512)]                           'decoder_input_c[0][0]']     \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)       (None, None, 30)             15390     ['decoder_lstm[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1127454 (4.30 MB)\n",
            "Trainable params: 1127454 (4.30 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(decoder_model, show_shapes=False).create(prog='dot', format='svg'))\n",
        "\n",
        "plot_model(\n",
        "    model=decoder_model, show_shapes=False,\n",
        "    to_file='decoder.pdf'\n",
        ")\n",
        "\n",
        "decoder_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOtU5CtEedCh"
      },
      "source": [
        "### 3.3. Connect the encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkDfv0W6edCi"
      },
      "outputs": [],
      "source": [
        "# input layers\n",
        "encoder_input_x = Input(shape=(None, num_encoder_tokens), name='encoder_input_x')\n",
        "decoder_input_x = Input(shape=(None, num_decoder_tokens), name='decoder_input_x')\n",
        "\n",
        "# connect encoder to decoder\n",
        "encoder_final_states = encoder_model([encoder_input_x])\n",
        "decoder_lstm_output, _, _ = decoder_lstm(decoder_input_x, initial_state=encoder_final_states)\n",
        "decoder_pred = decoder_dense(decoder_lstm_output)\n",
        "\n",
        "model = Model(inputs=[encoder_input_x, decoder_input_x],\n",
        "              outputs=decoder_pred,\n",
        "              name='model_training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiFx6us1edCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4901cab-142a-4802-c60e-842c821a9178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_training\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input_x (InputLaye  [(None, None, 28)]           0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " decoder_input_x (InputLaye  [(None, None, 30)]           0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " encoder (Functional)        [(None, 512),                583680    ['encoder_input_x[0][0]']     \n",
            "                              (None, 512)]                                                        \n",
            "                                                                                                  \n",
            " decoder_lstm (LSTM)         [(None, None, 512),          1112064   ['decoder_input_x[0][0]',     \n",
            "                              (None, 512),                           'encoder[0][0]',             \n",
            "                              (None, 512)]                           'encoder[0][1]']             \n",
            "                                                                                                  \n",
            " decoder_dense (Dense)       (None, None, 30)             15390     ['decoder_lstm[1][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1711134 (6.53 MB)\n",
            "Trainable params: 1711134 (6.53 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils import model_to_dot, plot_model\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=False).create(prog='dot', format='svg'))\n",
        "\n",
        "plot_model(\n",
        "    model=model, show_shapes=False,\n",
        "    to_file='model_training.pdf'\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8EfV2uWedCi"
      },
      "source": [
        "### 3.4. Fit the model on the bilingual dataset\n",
        "\n",
        "- encoder_input_data: one-hot encode of the input language\n",
        "\n",
        "- decoder_input_data: one-hot encode of the input language\n",
        "\n",
        "- decoder_target_data: labels (left shift of decoder_input_data)\n",
        "\n",
        "- tune the hyper-parameters\n",
        "\n",
        "- stop when the validation loss stop decreasing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QodbY073edCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6832ef0-d5f5-4697-cdeb-2c7ad2029a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of encoder_input_data(20000, 18, 28)\n",
            "shape of decoder_input_data(20000, 48, 30)\n",
            "shape of decoder_target_data(20000, 48, 30)\n"
          ]
        }
      ],
      "source": [
        "print('shape of encoder_input_data' + str(encoder_input_data.shape))\n",
        "print('shape of decoder_input_data' + str(decoder_input_data.shape))\n",
        "print('shape of decoder_target_data' + str(decoder_target_data.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aq-ljb-TedCi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1067e73a-4e00-4fde-c280-b5de3ef7f025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 17s 28ms/step - loss: 1.0931 - val_loss: 1.0987\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 6s 25ms/step - loss: 0.9045 - val_loss: 0.9530\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 5s 21ms/step - loss: 0.8503 - val_loss: 0.9039\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.8277 - val_loss: 0.8735\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.8149 - val_loss: 0.8509\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.8029 - val_loss: 0.8493\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7913 - val_loss: 0.8168\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7804 - val_loss: 0.8006\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.7715 - val_loss: 0.7973\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7635 - val_loss: 0.7751\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.7542 - val_loss: 0.7595\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.7469 - val_loss: 0.7551\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.7389 - val_loss: 0.7427\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.7321 - val_loss: 0.7361\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.7231 - val_loss: 0.7197\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.7162 - val_loss: 0.7164\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.7108 - val_loss: 0.7028\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.7041 - val_loss: 0.6966\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6967 - val_loss: 0.6893\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6930 - val_loss: 0.6818\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.6852 - val_loss: 0.6750\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6803 - val_loss: 0.6653\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.6746 - val_loss: 0.6576\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6722 - val_loss: 0.6571\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6648 - val_loss: 0.6527\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 5s 18ms/step - loss: 0.6596 - val_loss: 0.6388\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6564 - val_loss: 0.6391\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6510 - val_loss: 0.6325\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 4s 18ms/step - loss: 0.6444 - val_loss: 0.6273\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6407 - val_loss: 0.6216\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6380 - val_loss: 0.6203\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.6332 - val_loss: 0.6163\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6278 - val_loss: 0.6123\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6240 - val_loss: 0.6045\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.6204 - val_loss: 0.6104\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.6175 - val_loss: 0.5996\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.6132 - val_loss: 0.5985\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6081 - val_loss: 0.5912\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.6048 - val_loss: 0.5910\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.6008 - val_loss: 0.5862\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 5s 20ms/step - loss: 0.5998 - val_loss: 0.5812\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 6s 24ms/step - loss: 0.5937 - val_loss: 0.5820\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 6s 22ms/step - loss: 0.5912 - val_loss: 0.5761\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.5858 - val_loss: 0.5708\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.5827 - val_loss: 0.5699\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.5796 - val_loss: 0.5681\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.5750 - val_loss: 0.5663\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 5s 19ms/step - loss: 0.5736 - val_loss: 0.5629\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.5707 - val_loss: 0.5631\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.5675 - val_loss: 0.5621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "model.fit([encoder_input_data, decoder_input_data],  # training data\n",
        "          decoder_target_data,                       # labels (left shift of the target sequences)\n",
        "          batch_size=64, epochs=50, validation_split=0.2)\n",
        "\n",
        "model.save('seq2seq.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIHRh9L3edCi"
      },
      "source": [
        "## 4. Make predictions\n",
        "\n",
        "- In this section, you need to complete section 4.2 to translate English to the target language.\n",
        "\n",
        "\n",
        "### 4.1. Translate English to XXX\n",
        "\n",
        "1. Encoder read a sentence (source language) and output its final states, $h_t$ and $c_t$.\n",
        "2. Take the [star] sign \"\\t\" and the final state $h_t$ and $c_t$ as input and run the decoder.\n",
        "3. Get the new states and predicted probability distribution.\n",
        "4. sample a char from the predicted probability distribution\n",
        "5. take the sampled char and the new states as input and repeat the process (stop if reach the [stop] sign \"\\n\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jaq68T6EedCi"
      },
      "outputs": [],
      "source": [
        "# Reverse-lookup token index to decode sequences back to something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tjCXNCredCj"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
        "    print(\"num decod\", num_decoder_tokens)\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # this line of code is greedy selection\n",
        "        # try to use multinomial sampling instead (with temperature)\n",
        "        sampled_token_index = numpy.argmax(output_tokens[0, -1, :])\n",
        "\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = numpy.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OzAQb9FedCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11411e00-a96c-4707-84dd-2be56bc74283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 680ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 486ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        come see me\n",
            "Spanish (true):  venid a verme\n",
            "Spanish (pred):  ven a mira\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        come see me\n",
            "Spanish (true):  vengan a verme\n",
            "Spanish (pred):  ven a mira\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "-\n",
            "English:        come see me\n",
            "Spanish (true):  venga a verme\n",
            "Spanish (pred):  ven a mira\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        comfort tom\n",
            "Spanish (true):  consuela a tom\n",
            "Spanish (pred):  venidame a tomas\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        contact tom\n",
            "Spanish (true):  ponte en contacto con tom\n",
            "Spanish (pred):  no puedes ayudar\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "-\n",
            "English:        cook for me\n",
            "Spanish (true):  cociname\n",
            "Spanish (pred):  mara a mi masa\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "-\n",
            "English:        cook for me\n",
            "Spanish (true):  cocina para mi\n",
            "Spanish (pred):  mara a mi masa\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "English:        count me in\n",
            "Spanish (true):  cuenta conmigo\n",
            "Spanish (pred):  vo parme\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        count on it\n",
            "Spanish (true):  cuenta con eso\n",
            "Spanish (pred):  po puedes ester\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "-\n",
            "English:        count on it\n",
            "Spanish (true):  cuente con eso\n",
            "Spanish (pred):  po puedes ester\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "-\n",
            "English:        count on me\n",
            "Spanish (true):  cuenta conmigo\n",
            "Spanish (pred):  no puedes ayudar\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "English:        did tom die\n",
            "Spanish (true):  ha muerto tom\n",
            "Spanish (pred):  ha lo hace tom\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "English:        did tom run\n",
            "Spanish (true):  corrio tom\n",
            "Spanish (pred):  hazo tom\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "-\n",
            "English:        did tom try\n",
            "Spanish (true):  lo ha probado tom\n",
            "Spanish (pred):  hazo tom a tom\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "-\n",
            "English:        did tom try\n",
            "Spanish (true):  al final lo probo tom o no\n",
            "Spanish (pred):  hazo tom a tom\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "-\n",
            "English:        did tom try\n",
            "Spanish (true):  lo probo tom\n",
            "Spanish (pred):  hazo tom a tom\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "-\n",
            "English:        did tom win\n",
            "Spanish (true):  gano tom\n",
            "Spanish (pred):  hazlo a tom\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "-\n",
            "English:        did you win\n",
            "Spanish (true):  ganaste\n",
            "Spanish (pred):  te has cano\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "-\n",
            "English:        dig quickly\n",
            "Spanish (true):  cava rapido\n",
            "Spanish (pred):  me parmida\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "-\n",
            "English:        dig quickly\n",
            "Spanish (true):  cavad rapido\n",
            "Spanish (pred):  me parmida\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(2100, 2120):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('English:       ', input_texts[seq_index])\n",
        "    print('Spanish (true): ', target_texts[seq_index][1:-1])\n",
        "    print('Spanish (pred): ', decoded_sentence[0:-1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbJ49Be7edCj"
      },
      "source": [
        "### 4.2. Translate an English sentence to the target language （20 points）\n",
        "\n",
        "1. Tokenization\n",
        "2. One-hot encode\n",
        "3. Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPhY6DtxedCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "363849ce-f889-43e3-8855-eb16ccb6d66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "source sentence is: I love you\n",
            "translated sentence is: estoy en casa\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import tensorflow as tf\n",
        "\n",
        "input_sentence = 'I love you'\n",
        "\n",
        "#input_sequence = <do tokenization...>\n",
        "input_sequence, _ = text2sequences(max_encoder_seq_length, [input_sentence])\n",
        "\n",
        "#input_x = <do one-hot encode...>\n",
        "input_x = onehot_encode(input_sequence, max_encoder_seq_length, num_encoder_tokens)\n",
        "\n",
        "#translated_sentence = <do translation...>\n",
        "translated_sentence = decode_sequence(input_x)\n",
        "\n",
        "print('source sentence is: ' + input_sentence)\n",
        "print('translated sentence is: ' + translated_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URAfpeZ9edCj"
      },
      "source": [
        "# 5. Evaluate the translation using BLEU score\n",
        "\n",
        "- We have already translated from English to target language, but how can we evaluate the performance of our model quantitatively?\n",
        "\n",
        "- In this section, you need to re-train the model we built in section 3 and then evaluate the bleu score on testing dataset.\n",
        "\n",
        "Reference:\n",
        "\n",
        "https://machinelearningmastery.com/calculate-bleu-score-for-text-python/\n",
        "\n",
        "https://en.wikipedia.org/wiki/BLEU\n",
        "\n",
        "#### Hint:\n",
        "\n",
        "- Randomly partition the dataset to training, validation, and test.\n",
        "\n",
        "- Evaluate the BLEU score using the test set. Report the average.\n",
        "\n",
        "- You may use packages to calculate bleu score, e.g., sentence_bleu() from nltk package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGsGGy8tedCj"
      },
      "source": [
        "### 5.1. Partition the dataset to training, validation, and test. Build new token index. (10 points)\n",
        "\n",
        "1. You may try to load more data/lines from text file.\n",
        "2. Convert text to sequences and build token index using training data.\n",
        "3. One-hot encode your training and validation text sequences."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 20000\n",
        "clean_pairs = clean_data(pairs)[0:num_samples, :]\n",
        "input_texts = clean_pairs[:,0]\n",
        "print(clean_pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxAhjFGfIJNW",
        "outputId": "71c766fa-ab1d-4296-9908-9790609b4102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['go' 've' 'ccby france attribution tatoebaorg cm cueyayotl']\n",
            " ['go' 'vete' 'ccby france attribution tatoebaorg cm cueyayotl']\n",
            " ['go' 'vaya' 'ccby france attribution tatoebaorg cm cueyayotl']\n",
            " ...\n",
            " ['dont fall please' 'no te caigas por favor'\n",
            "  'ccby france attribution tatoebaorg arh']\n",
            " ['dont feed the dog' 'no des de comer al perro'\n",
            "  'ccby france attribution tatoebaorg ck shishir']\n",
            " ['dont get it wrong' 'no me malentiendas'\n",
            "  'ccby france attribution tatoebaorg end marcelostockle']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_texts.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WsY2GGGZ8OC",
        "outputId": "ed6af326-da42-44b7-ae53-b097a2d52735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_texts = ['\\t' + text + '\\n' for text in clean_pairs[:, 1]]"
      ],
      "metadata": {
        "id": "FVta-wT7KGCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_encoder_seq_length = max(len(line) for line in input_texts) # finding the max length of input texts\n",
        "max_decoder_seq_length = max(len(line) for line in target_texts) # finding the max length of target texts\n",
        "\n",
        "print(max_encoder_seq_length)\n",
        "print(max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcX1wDA2bC6g",
        "outputId": "3e5d60df-7686-4032-c8b5-299b3c1f545e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# establishing max_ecoder_seq_length / helps to optimize and use less memory\n",
        "\n",
        "# max_encoder_seq_length = max(len(input_texts) for line in input_texts) # finding the max length of input texts\n",
        "# max_decoder_seq_length = max(len(target_texts) for line in target_texts) # finding the max length of target texts\n",
        "\n",
        "# Process input and target texts, every input is tokenized array of characters\n",
        "encoder_input_seq, input_token_index = text2sequences(max_encoder_seq_length, input_texts)\n",
        "decoder_input_seq, target_token_index = text2sequences(max_decoder_seq_length, target_texts)\n",
        "print(encoder_input_seq[0])\n",
        "print(input_token_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYRlMO3GK_kJ",
        "outputId": "1c4caeaa-4870-42f6-ded9-6fdb285feca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            "{' ': 1, 'e': 2, 't': 3, 'o': 4, 'i': 5, 'a': 6, 's': 7, 'n': 8, 'h': 9, 'r': 10, 'm': 11, 'l': 12, 'd': 13, 'y': 14, 'u': 15, 'w': 16, 'c': 17, 'g': 18, 'k': 19, 'p': 20, 'b': 21, 'f': 22, 'v': 23, 'j': 24, 'x': 25, 'z': 26, 'q': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_input_tokens = len(input_token_index) + 1\n",
        "num_target_tokens = len(target_token_index) + 1\n",
        "\n",
        "# one-hot encoding training and validation sequence\n",
        "encoder_input_data = onehot_encode(encoder_input_seq, max_encoder_seq_length, num_input_tokens)\n",
        "target_input_data = onehot_encode(decoder_input_seq, max_decoder_seq_length, num_target_tokens)\n",
        "\n",
        "decoder_target_seq = numpy.zeros(decoder_input_seq.shape)\n",
        "decoder_target_seq[:, 0:-1] = decoder_input_seq[:, 1:]\n",
        "decoder_target_data = onehot_encode(decoder_target_seq,\n",
        "                                    max_decoder_seq_length,\n",
        "                                    num_target_tokens)\n",
        "\n",
        "# # Adjusting the max lengths and vocab sizes for decoder targets\n",
        "# decoder_target_seq = numpy.zeros(train_decoder_input_seq.shape)\n",
        "# decoder_target_seq[:, 0:-1] = train_decoder_input_seq[:, 1:]\n",
        "# decoder_target_data = onehot_encode(decoder_target_seq, max_decoder_seq_length, num_decoder_tokens)\n",
        "\n",
        "# print(\"Shape of encoder input data:\", encoder_input_data.shape)\n",
        "# print(\"Shape of decoder input data:\", target_input_data.shape)"
      ],
      "metadata": {
        "id": "OpAhwbBTTWUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"encoder\", encoder_input_data.shape)\n",
        "print(\"targer\", target_input_data.shape)\n",
        "print(\"decoder\", decoder_target_seq.shape)\n",
        "print(\"decoder t\", decoder_target_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WdeJTjUbuqF",
        "outputId": "cfe4dd5b-f079-48fc-ff0e-84de64d0f0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder (20000, 18, 28)\n",
            "targer (20000, 48, 30)\n",
            "decoder (20000, 48)\n",
            "decoder t (20000, 48, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KSF8LkeedCj"
      },
      "outputs": [],
      "source": [
        "from operator import index\n",
        "## Partitioning the dataset to trainning, validation and test sets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#indices\n",
        "indices = np.arange(len(encoder_input_seq)) # getting length\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Split indices\n",
        "train_indices, temp_indices = train_test_split(indices, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
        "\n",
        "# Split into indices into validation and test sets\n",
        "validation_indices, test_indices = train_test_split(temp_indices, test_size=0.5, random_state=42)  # 10% validation, 10% test\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train\", train_indices.shape)\n",
        "print(\"Validation\", validation_indices.shape)\n",
        "print(\"test\", test_indices.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkrea0KyXq9m",
        "outputId": "8a345598-7aee-431c-d637-cd3c6669c514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (16000,)\n",
            "Validation (2000,)\n",
            "test (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCJp-yHpedCj"
      },
      "source": [
        "### 5.2 Retrain your previous Bidirectional LSTM model with training and validation data and tune the parameters (learning rate, optimizer, etc) based on validation score. (25 points)\n",
        "\n",
        "1. Use the model structure in section 3 to train a new model with new training and validation datasets.\n",
        "2. Based on validation BLEU score or loss to tune parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABoQ52KGedCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa5632ef-fb49-4b26-cb2c-86569513ea10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "250/250 [==============================] - 10s 16ms/step - loss: 1.1267\n",
            "Epoch 2/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.9327\n",
            "Epoch 3/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8802\n",
            "Epoch 4/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.8594\n",
            "Epoch 5/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8444\n",
            "Epoch 6/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8324\n",
            "Epoch 7/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.8195\n",
            "Epoch 8/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.8095\n",
            "Epoch 9/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7992\n",
            "Epoch 10/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7906\n",
            "Epoch 11/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7819\n",
            "Epoch 12/50\n",
            "250/250 [==============================] - 4s 17ms/step - loss: 0.7723\n",
            "Epoch 13/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7651\n",
            "Epoch 14/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7579\n",
            "Epoch 15/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7486\n",
            "Epoch 16/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7419\n",
            "Epoch 17/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7352\n",
            "Epoch 18/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7284\n",
            "Epoch 19/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7225\n",
            "Epoch 20/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.7178\n",
            "Epoch 21/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7117\n",
            "Epoch 22/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.7059\n",
            "Epoch 23/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6999\n",
            "Epoch 24/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6931\n",
            "Epoch 25/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6907\n",
            "Epoch 26/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6835\n",
            "Epoch 27/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6784\n",
            "Epoch 28/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6741\n",
            "Epoch 29/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6706\n",
            "Epoch 30/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6658\n",
            "Epoch 31/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6620\n",
            "Epoch 32/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6571\n",
            "Epoch 33/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6519\n",
            "Epoch 34/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6474\n",
            "Epoch 35/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6452\n",
            "Epoch 36/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6380\n",
            "Epoch 37/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6346\n",
            "Epoch 38/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6318\n",
            "Epoch 39/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6287\n",
            "Epoch 40/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6245\n",
            "Epoch 41/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6208\n",
            "Epoch 42/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6161\n",
            "Epoch 43/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.6143\n",
            "Epoch 44/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6090\n",
            "Epoch 45/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6064\n",
            "Epoch 46/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.6042\n",
            "Epoch 47/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.5998\n",
            "Epoch 48/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.5961\n",
            "Epoch 49/50\n",
            "250/250 [==============================] - 4s 15ms/step - loss: 0.5929\n",
            "Epoch 50/50\n",
            "250/250 [==============================] - 4s 16ms/step - loss: 0.5906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ef964504ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "#training the model\n",
        "model.fit([encoder_input_data[train_indices], decoder_input_data[train_indices]], decoder_target_data[train_indices],\n",
        "          batch_size=64, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSuz_DicedCk"
      },
      "source": [
        "### 5.3 Evaluate the BLEU score using the test set. (15 points)\n",
        "\n",
        "1. Use trained model above to calculate the BLEU score with testing dataset.\n",
        "2. A reasonable value should be 0.1-0.3. The higher, the better."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vals = validation_indices[:20]\n",
        "data_vals = decoder_input_data[vals]\n",
        "print(data_vals.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mako8LzugGCp",
        "outputId": "e3db6c2c-d2a1-496f-c802-1d0ab4691439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 48, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = encoder_input_data[vals]\n",
        "\n",
        "def targetss(target_texts, vals):\n",
        "  actual = []\n",
        "  for i in range(len(vals)):\n",
        "    actual.append(target_texts[vals[i]])\n",
        "  return actual\n",
        "\n",
        "targets = targetss(target_texts, vals)"
      ],
      "metadata": {
        "id": "q-eqXRixi8bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(values.shape)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7ek9AlakhzD",
        "outputId": "ab4a610e-5418-497f-fe97-510a29bf5988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 18, 28)\n",
            "['\\tyo no estaba alli\\n', '\\tpuedo ir a trabajar\\n', '\\tella esta a dieta\\n', '\\ttom mintio\\n', '\\tella tiene un libro\\n', '\\tdije la verdad\\n', '\\tresuelva el problema\\n', '\\testoy acatarrado\\n', '\\tno es suficiente\\n', '\\trecuerdamelo mas tarde\\n', '\\ta el le va bien\\n', '\\tme encanta mi trabajo\\n', '\\tpruebate estos\\n', '\\tespera que llamo a tom\\n', '\\testa estropeado\\n', '\\thay mas\\n', '\\tte sientes culpable\\n', '\\testos zapatos me lastiman\\n', '\\testamos de vacaciones\\n', '\\tnadie me ha ensenado\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIwpAcGLedCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c6ead8-5ba1-4e8d-ce53-1c1f22a9dd44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 162ms/step\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Average BLEU score on the test set: 0.20202320387698042\n"
          ]
        }
      ],
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# def evaluate_bleu(model, test_pairs, input_token_index, target_token_index, max_encoder_seq_length, max_decoder_seq_length):\n",
        "#     scores = []\n",
        "#     for input_text, target_text in test_pairs:\n",
        "#         input_seq, _ = text2sequences(max_encoder_seq_length, [input_text])\n",
        "#         input_x = onehot_encode(input_seq, max_encoder_seq_length, len(input_token_index) + 1)\n",
        "#         translated_sentence = decode_sequence(input_x)\n",
        "#         reference = target_text.split()\n",
        "#         candidate = translated_sentence.strip().split()\n",
        "#         score = sentence_bleu([reference], candidate)\n",
        "#         scores.append(score)\n",
        "#     return numpy.mean(scores)\n",
        "\n",
        "def evaluate_bleu(actual, encoder_input_data):\n",
        "    scores = []\n",
        "\n",
        "    #actual = input\n",
        "    for i in range(len(actual)):\n",
        "      input_seq = encoder_input_data[i: i + 1]\n",
        "      decoded_sentence = decode_sequence(input_seq)\n",
        "\n",
        "      scores.append(sentence_bleu([actual[i]], decoded_sentence))\n",
        "\n",
        "\n",
        "    return numpy.mean(scores)\n",
        "\n",
        "# Calculate the average BLEU score on the test set\n",
        "average_bleu_score = evaluate_bleu(targets, values)\n",
        "print(\"Average BLEU score on the test set:\", average_bleu_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train on testing data\n",
        "\n",
        "vali = test_indices[:20]\n",
        "data_values = decoder_input_data[vali]\n",
        "print(data_values.shape)\n",
        "\n",
        "valuess = encoder_input_data[vali]\n",
        "\n",
        "targets = targetss(target_texts, vali)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44S3vcJQmoSm",
        "outputId": "4ef2d7a8-497a-429c-e631-8488d0ef591d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20, 48, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average BLEU score on the test set\n",
        "average_bleu_score = evaluate_bleu(targets, valuess)\n",
        "print(\"Average BLEU score on the test set:\", average_bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyEHS-BvnXaC",
        "outputId": "b9addec5-7871-4254-8571-251c346700d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 29ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "num decod 30\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Average BLEU score on the test set: 0.2843368574806425\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}